<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Luke Ellis | Projects</title>
    <link rel="stylesheet" href="style.css" />
  </head>

  <body>
    <header>
      <div class="header-text">
        <h1>Luke <span>Ellis</span> <small>Data Professional</small></h1>
      </div>
    </header>

    <nav>
      <a href="index.html">About</a>
      <a href="experience.html">Experience</a>
      <a href="skills.html">Skills</a>
      <a href="projects.html">Projects</a>
      <a href="contact.html">Contact Me</a>
    </nav>

    <main>
      <section class="projects-section">
        <h2>Projects</h2>

        <div class="projects-grid">
          <!-- Project 1 -->
          <div class="project-card" onclick="openModal('projectModal')">
            <h3>NFL 2025 Big Data Bowl</h3>
            <p>
              Developed a random forest classifier to predict the probability of
              designed run plays vs. pass plays for the San Francisco 49ers.
            </p>
          </div>

          <!-- Project 2 -->
          <div class="project-card" onclick="openModal('etlModal')">
            <h3>ETL Pipeline</h3>
            <p>
              Built an ETL pipeline that transforms Community Transit’s public 
              GTFS data into a relational database using Python and PostgreSQL.
            </p>
          </div>
        </div>
      </section>

      <!-- Modal for NFL Project -->
      <div id="projectModal" class="modal">
        <div class="modal-content">
          <span class="close" onclick="closeModal('projectModal')"
            >&times;</span
          >

          <h2>NFL 2025 Big Data Bowl</h2>

          <h3>Overview</h3>
          <p>
            This machine learning model was developed to give NFL defenses a
            competitive advantage against the San Francisco 49ers by predicting
            the probability of designed run plays versus pass plays based on
            pre-snap alignment and game situation. The model enables defensive
            coordinators to make informed audibles that could disrupt offensive
            strategies.
          </p>

          <h3>Data Source & Processing</h3>
          <p>
            The dataset was supplied by the NFL, covering weeks 1-6 of the 2023
            season and focusing exclusively on San Francisco's offensive plays.
            After removing QB kneels and compressing data by gameID and playID,
            the final dataset contained 451 plays across seven engineered
            features. This clean, focused dataset provided a robust foundation
            for training the predictive model.
          </p>

          <h3>Target Variable</h3>
          <p>
            The target variable is binary: (1) for designed running plays and
            (0) for pass plays. To emphasize strategic play-calling analysis, QB
            scrambles were excluded from designed runs, ensuring the model
            focused on intentional offensive schemes rather than impromptu
            decisions.
          </p>

          <h3>Model Architecture & Performance</h3>
          <p>
            The random forest classifier was selected for its ability to handle
            the imbalanced dataset (194 run plays vs. 257 pass plays) using
            class weights to prevent bias. The model achieved strong performance
            metrics with 80.9% accuracy and 87.4% ROC AUC. Given the high cost
            of defensive misalignment, the model prioritized precision,
            achieving 81% accuracy for pass plays and 79% for run plays.
          </p>

          <div class="performance-metrics">
            <h4>Classification Results:</h4>
            <pre>
                    precision    recall  f1-score   support
            Pass       0.82      0.84      0.83        77
            Run        0.79      0.76      0.78        59
            </pre>
          </div>

          <h3>Feature Engineering & Selection</h3>
          <p>
            Features were selected based on factors that significantly influence
            offensive play-calling decisions. Each feature underwent appropriate
            preprocessing techniques:
          </p>

          <ul>
            <li>
              <strong>offenseFormation (17.76% SHAP importance)</strong> – Six
              formation types (SHOTGUN, SINGLEBACK, I_FORM, etc.) processed
              through OneHotEncoding after removing null values.
            </li>
            <li>
              <strong>motionSinceLineset (12.24%)</strong> – Boolean indicator
              of player motion after line set, with nulls imputed using KNN and
              binary encoding applied.
            </li>
            <li>
              <strong>receiverAlignment (8.81%)</strong> – Categorical alignment
              patterns (0x0, 1x1, 2x1, etc.) processed through OneHotEncoding.
            </li>
            <li>
              <strong>presnap_score_difference (3.79%)</strong> – Engineered
              feature capturing score-based play-calling tendencies (positive
              when SF leads, negative when trailing), standardized for model
              input.
            </li>
            <li>
              <strong>down_yardsToGo (3.54%)</strong> – Custom feature
              multiplying down number by yards to go, creating an expanded scale
              that penalizes late downs with high yardage needs.
            </li>
            <li>
              <strong>gameClock_seconds (2.04%)</strong> – Game clock converted
              from MM:SS format to seconds and standardized.
            </li>
            <li>
              <strong>shiftSinceLineset (2.00%)</strong> – Boolean indicating
              player shifts greater than 2.5 yards from line set position,
              binary encoded after dropping null values.
            </li>
          </ul>

          <h3>Feature Correlation Analysis</h3>
          <p>
            Correlation analysis revealed clear patterns distinguishing run vs.
            pass tendencies:
          </p>
          <div class="correlation-data">
            <h4>Strong Run Indicators (Positive Correlation):</h4>
            <ul>
              <li>I_FORM formation (0.407)</li>
              <li>2x1 receiver alignment (0.384)</li>
              <li>Positive score difference (0.282)</li>
              <li>SINGLEBACK formation (0.227)</li>
            </ul>

            <h4>Strong Pass Indicators (Negative Correlation):</h4>
            <ul>
              <li>SHOTGUN formation (-0.379)</li>
              <li>High down/yards combinations (-0.349)</li>
              <li>Motion since line set (-0.287)</li>
              <li>EMPTY formation (-0.278)</li>
            </ul>
          </div>

          <h3>Hyperparameter Optimization</h3>
          <p>
            The model underwent iterative hyperparameter tuning using grid
            search, optimizing for ROC AUC and precision. Cross-validation
            monitoring prevented overfitting, achieving a mean CV score of 88.4%
            with low variability (2.6% standard deviation).
          </p>

          <div class="hyperparameters">
            <h4>Optimal Parameters:</h4>
            <ul>
              <li>bootstrap: False</li>
              <li>max_depth: 10</li>
              <li>max_features: 'sqrt'</li>
              <li>min_samples_leaf: 2</li>
              <li>min_samples_split: 25</li>
              <li>n_estimators: 300</li>
            </ul>
          </div>

          <h3>Model Validation & Learning Curves</h3>
          <div class="project-graphs">
            <img src="assets/graph1.jpg" alt="Confusion Matrix" />
            <img src="assets/graph2.jpg" alt="ROC Curve" />
            <img src="assets/graph3.jpg" alt="Learning Curve" />
          </div>
          <p>
            The learning curve analysis shows strong model performance with
            training data fitting well as dataset size increases. A slight gap
            between training and validation scores suggests minor overfitting
            that could benefit from additional training data. Both curves level
            off, indicating the model has reached a performance plateau with
            current data volume.
          </p>

          <h3>Practical Applications & Business Impact</h3>
          <p>
            This model provides defensive coordinators with actionable
            intelligence to anticipate offensive play calls with 80.9% accuracy.
            The high confidence intervals enable real-time defensive adjustments
            that could significantly impact game outcomes, particularly in
            critical down-and-distance situations.
          </p>

          <h3>Limitations & Future Enhancements</h3>
          <p>
            While the model demonstrates strong predictive capability, several
            areas present opportunities for improvement. Weekly retraining would
            be essential to capture evolving team tendencies throughout the
            season, with potential implementation of time-decay weighting to
            emphasize recent games. Future iterations could incorporate player
            personnel packages, injury reports, and specific player tendencies
            (e.g., Christian McCaffrey's presence) to enhance prediction
            accuracy and provide more granular insights for defensive strategy.
          </p>
        </div>
      </div>

      <!-- ETL Pipeline Modal -->
      <div id="etlModal" class="modal">
        <div class="modal-content">
          <span class="close" onclick="closeModal('etlModal')">&times;</span>

          <h2>Community Transit ETL Pipeline</h2>

          <h3>Overview</h3>
          <p>
            This pipeline extracts raw GTFS publicly available data from Community 
            Transit’s website and transforms it into a database that is ready for 
            data analytics. Two procedures are also included to maintain the pipeline, 
            one to remove old calendar dates to save storage space and the other to 
            identify null values so the data can be fixed. 
          </p>

          <h3>Architecture</h3>
          <p>
            The database naturally uses the GTFS relationships, the trips table is the 
            central table since it has two foreign keys. The stop_times table uses a 
            composite primary key of trip_id and stop_sequence. Indexes were created on 
            foreign keys and common fields to optimize search time.
          </p>

          <div class="project-graphs">
            <img
              src="assets/ETL_Dag.jpg"
              alt="ETL Pipeline Architecture Diagram"
            />
          </div>
          
          <div class="performance-metrics">
            <h3>Table Structure</h3>
            <p>
                <strong>routes:</strong> Contains all transit routes with route_id 
                as the primary key. The feature created_at is added to show the ingestion 
                timestamp.
              </li>
              <p>
                <strong>calendar:</strong> Contains the service schedule for transit operations. 
                Uses a boolean for monday-sunday to show which days are in operation. The feature 
                created_at is added to show the ingestion timestamp.
              </li>
              <p>
                <strong>trips:</strong> Contains individual trips with trip_id as the primary key. 
                The feature created_at is added to show the ingestion timestamp.
              </li>
              <p>
                <strong>stops:</strong> Contains all bus stops including GPS coordinates for each stop. 
                The load function will remove any coordinates that are incorrect. Added the feature 
                wheelchair_boarding which is defaulted to true (1). The feature created_at is added to 
                show the ingestion timestamp.
              </li>
              <p>
                <strong>stop_times:</strong> Contains every scheduled stop for every trip. Uses a composite 
                primary key of trip_id and stop_sequence. The feature created_at is added to show the ingestion timestamp.
              </li>
            </ul>
          </div>

          <h3>ETL Process</h3>
          <p>
            The pipeline consists of two main Python scripts that are executed in sequence. 
            </li>
            </p>
            <p>
            1.	extract_data.py: Downloads the GTFS data from Community Transit’s websites. 
            The script extracts the data from the zip file and stores it in a local folder. 
            </li>
            <p>
            2.	load_data.py: Loads the specific data into their designated tables. 

          </p>
          <div class="hyperparameters">
            <h3>Maintenance Procedures</h3>
            <p>
                <strong>delete_old_calendar_data:</strong> Automatically removes
                calendar data older than one year to optimize storage space and
                query performance
              </li>
              <p>
                <strong>check_null_values:</strong> Systematically scans all
                tables and columns to identify null values, providing detailed
                reports on data completeness for proactive quality management
              </li>
            </ul>
          </div>

    </main>

    <footer>
      <p>&copy; 2025 Luke Ellis</p>
    </footer>

    <script>
      function openModal(id) {
        document.getElementById(id).style.display = "block";
      }

      function closeModal(id) {
        document.getElementById(id).style.display = "none";
      }

      window.onclick = function (event) {
        const modals = document.querySelectorAll(".modal");
        modals.forEach((modal) => {
          if (event.target === modal) {
            modal.style.display = "none";
          }
        });
      };
    </script>
  </body>
</html>